{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38f96ecd-cd15-4027-beb4-963b8caa5042",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset, concatenate_datasets\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1866f6f9-ae6d-4984-a302-ad9838181084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b766fa9c304f445a8c60703b70a2e62e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device=\"cuda\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98e70dfa-8457-4ad9-bda2-24a2af9d760b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "#                                              torch_dtype=torch.bfloat16,\n",
    "#                                              device_map=\"auto\"\n",
    "#                                             )\n",
    "# tokenizer = AutoTokenizer.from_pretrained('ZWG817/Llama3_Chat_Materials')\n",
    "# model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# model.load_adapter('ZWG817/Llama3_Chat_Materials')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fef5cacf-bf1e-4612-bfb9-f3304d92be9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = load_dataset(\"ZWG817/Materials_Gilbert_Damping\")\n",
    "data_train = data[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ccfed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are a helpful assistant. Read the following text and determine if it mentions the Gilbert damping constant of any material. If it does, list each material's molecular formula and its corresponding Gilbert damping constant. Please format your answer as follows:\\nChemical Formula: [Formula]\\nGilbert Damping Constant: [Value]\\nOriginal Sentences: [Sentences]\\nIf the text does not mention the Gilbert damping constant, please respond with:\\nNo Mention\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da87034b-a301-4aee-8e13-dcd9b42c79e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": data_train[4]['content'][:20000]},\n",
    "]\n",
    "\n",
    "terminators = [\n",
    "    pipe.tokenizer.eos_token_id,\n",
    "    pipe.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "outputs = pipe(\n",
    "    messages,\n",
    "    max_new_tokens=2048,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    ")\n",
    "assistant_response = outputs[-1][\"generated_text\"][-1][\"content\"]\n",
    "print(assistant_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90df1442-3308-4b6c-845e-5e590faae46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df_tmp = pd.DataFrame()\n",
    "df['Damping Constant'] = []\n",
    "results = []\n",
    "\n",
    "for i,j in enumerate(data_train):\n",
    "    print(i)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": data_train[i]['content'][:20000]},\n",
    "    ]\n",
    "    \n",
    "    terminators = [\n",
    "        pipe.tokenizer.eos_token_id,\n",
    "        pipe.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "    ]\n",
    "    try:\n",
    "        outputs = pipe(\n",
    "            messages,\n",
    "            max_new_tokens=2048,\n",
    "            eos_token_id=terminators,\n",
    "            do_sample=True,\n",
    "            temperature=0.6,\n",
    "            top_p=0.9,\n",
    "        )\n",
    "\n",
    "        assistant_response = outputs[-1][\"generated_text\"][-1][\"content\"]\n",
    "        print(assistant_response)\n",
    "        results.append(assistant_response)\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    if len(results) % 500 == 0:\n",
    "        df_tmp['Damping Constant'] = pd. Series(results)\n",
    "        df = pd.concat([df,df_tmp])\n",
    "        results = []\n",
    "        df_tmp = pd.DataFrame()\n",
    "        df = df.reset_index()[['Damping Constant']]\n",
    "        df.to_json('Gilbert Damping Constant'+str(i)+'.json')\n",
    "        # df.to_csv('Gilbert Damping Constant.csv',index = False)\n",
    "    \n",
    "    if i >= 20:\n",
    "        break\n",
    "    \n",
    "df_tmp['Damping Constant'] = results\n",
    "df = pd.concat([df,df_tmp])\n",
    "df = df.reset_index()[['Damping Constant']]\n",
    "df.to_json('Gilbert Damping Constant.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f766c3c2-6502-4278-aff3-ad566f1854d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff45672-14d3-4dd5-a9c3-c99838bd66f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.save_pretrained('result', save_embedding_layers=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
