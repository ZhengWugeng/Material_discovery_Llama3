{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments\n",
    "from datasets import load_dataset, Dataset, concatenate_datasets\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "from trl import SFTTrainer\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login --token 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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddc53950578d4db282771899ad0f84f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'meta-llama/Meta-Llama-3-8B'\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                             #load_in_8bit=True,\n",
    "                                             torch_dtype=torch.bfloat16,\n",
    "                                             device_map=\"auto\"\n",
    "                                            )\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"meta-llama/Meta-Llama-3-8B\"\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "#                                              torch_dtype=torch.bfloat16,\n",
    "#                                              device_map=\"auto\"\n",
    "#                                             )\n",
    "# tokenizer = AutoTokenizer.from_pretrained('ZWG817/Llama3_Chat_Materials')\n",
    "# model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# model.load_adapter('ZWG817/Llama3_Chat_Materials')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['title', 'content'],\n",
      "    num_rows: 2365\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "data = load_dataset(\"ZWG817/FullContent\")\n",
    "data_train = data[\"train\"]\n",
    "print(data_train)\n",
    "\n",
    "#custom_data = load_dataset('json', data_files='data_eval.json')\n",
    "#data_val = custom_data['train']\n",
    "\n",
    "with open('materials.txt', 'r') as file:\n",
    "    word_list = file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1512.03112v2.Hall_effect_and_Fermi_surface_rec...</td>\n",
       "      <td>arXiv:1512.03112v2  [cond-mat.supr-con]  9 Feb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009.14550v2.Out_of_plane_transport_of_1T_TaS2...</td>\n",
       "      <td>\\n1 \\n Out-of-plane transport of 1T -TaS 2/g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1011.3934v1.Effect_of_electron_phonon_coupling...</td>\n",
       "      <td>E\u000b",
       "ect of electron-phonon coupling on transmiss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2108.06226v2.Giant_nonlinear_response_due_to_u...</td>\n",
       "      <td>Giant nonlinear response due to unconventional...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003.04501v1.Experimental_observations_indicat...</td>\n",
       "      <td>\\nExperimental observations indicating  the t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2360</th>\n",
       "      <td>0904.2164v2.Chiral_asymmetry_of_the_Fermi_surf...</td>\n",
       "      <td>arXiv:0904.2164v2  [hep-ph]  15 Sep 2009Chiral...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2361</th>\n",
       "      <td>1509.07865v1.Composite_fermions_and_the_field_...</td>\n",
       "      <td>Composite fermions and the \f",
       "eld-tuned supercon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2362</th>\n",
       "      <td>1007.2058v1.Modeling_of_complex_oxide_material...</td>\n",
       "      <td>arXiv:1007.2058v1  [cond-mat.str-el]  13 Jul 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2363</th>\n",
       "      <td>0804.0001v1.2D_skew_scattering_in_the_vicinity...</td>\n",
       "      <td>arXiv:0804.0001v1  [cond-mat.mes-hall]  31 Mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2364</th>\n",
       "      <td>2401.15302v1.On_the_origin_of_metal_insulator_...</td>\n",
       "      <td>On the origin of metal-insulator transitions i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2365 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0     1512.03112v2.Hall_effect_and_Fermi_surface_rec...   \n",
       "1     2009.14550v2.Out_of_plane_transport_of_1T_TaS2...   \n",
       "2     1011.3934v1.Effect_of_electron_phonon_coupling...   \n",
       "3     2108.06226v2.Giant_nonlinear_response_due_to_u...   \n",
       "4     2003.04501v1.Experimental_observations_indicat...   \n",
       "...                                                 ...   \n",
       "2360  0904.2164v2.Chiral_asymmetry_of_the_Fermi_surf...   \n",
       "2361  1509.07865v1.Composite_fermions_and_the_field_...   \n",
       "2362  1007.2058v1.Modeling_of_complex_oxide_material...   \n",
       "2363  0804.0001v1.2D_skew_scattering_in_the_vicinity...   \n",
       "2364  2401.15302v1.On_the_origin_of_metal_insulator_...   \n",
       "\n",
       "                                                content  \n",
       "0     arXiv:1512.03112v2  [cond-mat.supr-con]  9 Feb...  \n",
       "1       \\n1 \\n Out-of-plane transport of 1T -TaS 2/g...  \n",
       "2     E\n",
       "ect of electron-phonon coupling on transmiss...  \n",
       "3     Giant nonlinear response due to unconventional...  \n",
       "4      \\nExperimental observations indicating  the t...  \n",
       "...                                                 ...  \n",
       "2360  arXiv:0904.2164v2  [hep-ph]  15 Sep 2009Chiral...  \n",
       "2361  Composite fermions and the \n",
       "eld-tuned supercon...  \n",
       "2362  arXiv:1007.2058v1  [cond-mat.str-el]  13 Jul 2...  \n",
       "2363  arXiv:0804.0001v1  [cond-mat.mes-hall]  31 Mar...  \n",
       "2364  On the origin of metal-insulator transitions i...  \n",
       "\n",
       "[2365 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data_train)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1210.1241v3.Electronic_structure_and_magnetism...</td>\n",
       "      <td>epl draft\\nCorrelation e\u000b",
       "ects and spin-orbit i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1411.2781v1.A_multi_scale_approach_to_the_elec...</td>\n",
       "      <td>A multi-scale approach to the electronic struc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>1708.04323v1.Robust_Determination_of_the_Chemi...</td>\n",
       "      <td>arXiv:1708.04323v1  [physics.comp-ph]  14 Aug ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1811.00776v1.First_principles_investigation_of...</td>\n",
       "      <td>1 \\n First -principles investigation of Ag -, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>2208.08898v1.Irida_Graphene__A_New_2D_Carbon_A...</td>\n",
       "      <td>Irida-Graphene: A New 2D Carbon Allotrope\\nM. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2308</th>\n",
       "      <td>2001.02042v2.Diverse_fundamental_properties_in...</td>\n",
       "      <td>Diverse fundamental properties in stage- n gra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2310</th>\n",
       "      <td>1703.04104v2.Electronic_origin_of_melting_T_P_...</td>\n",
       "      <td>\\n1Electronic origin of melting T â€“P curves o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2315</th>\n",
       "      <td>2005.08327v2.Remarkable_low_energy_properties_...</td>\n",
       "      <td>Remarkable low-energy properties of the pseudo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2323</th>\n",
       "      <td>1503.08951v1.Room_Temperature_Quantum_Spin_Hal...</td>\n",
       "      <td>Room Temperature Quantum Spin Hall Insulators ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2344</th>\n",
       "      <td>2208.12456v2.Quasiparticle_characteristics_of_...</td>\n",
       "      <td>Quasiparticle characteristics of the weakly fe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "21    1210.1241v3.Electronic_structure_and_magnetism...   \n",
       "31    1411.2781v1.A_multi_scale_approach_to_the_elec...   \n",
       "82    1708.04323v1.Robust_Determination_of_the_Chemi...   \n",
       "83    1811.00776v1.First_principles_investigation_of...   \n",
       "229   2208.08898v1.Irida_Graphene__A_New_2D_Carbon_A...   \n",
       "...                                                 ...   \n",
       "2308  2001.02042v2.Diverse_fundamental_properties_in...   \n",
       "2310  1703.04104v2.Electronic_origin_of_melting_T_P_...   \n",
       "2315  2005.08327v2.Remarkable_low_energy_properties_...   \n",
       "2323  1503.08951v1.Room_Temperature_Quantum_Spin_Hal...   \n",
       "2344  2208.12456v2.Quasiparticle_characteristics_of_...   \n",
       "\n",
       "                                                content  \n",
       "21    epl draft\\nCorrelation e\n",
       "ects and spin-orbit i...  \n",
       "31    A multi-scale approach to the electronic struc...  \n",
       "82    arXiv:1708.04323v1  [physics.comp-ph]  14 Aug ...  \n",
       "83    1 \\n First -principles investigation of Ag -, ...  \n",
       "229   Irida-Graphene: A New 2D Carbon Allotrope\\nM. ...  \n",
       "...                                                 ...  \n",
       "2308  Diverse fundamental properties in stage- n gra...  \n",
       "2310   \\n1Electronic origin of melting T â€“P curves o...  \n",
       "2315  Remarkable low-energy properties of the pseudo...  \n",
       "2323  Room Temperature Quantum Spin Hall Insulators ...  \n",
       "2344  Quasiparticle characteristics of the weakly fe...  \n",
       "\n",
       "[98 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target = df[df['content'].str.contains(\"/atom\")]\n",
    "# df_target = df[df['content'].str.replace(\"\\n\",\"\")].reset_index()[['title','content']]\n",
    "df_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n"
     ]
    }
   ],
   "source": [
    "target = []\n",
    "for i,j in enumerate(df_target['content']):\n",
    "    target.extend(re.findall(r'[A-Z].*[^(\\-|\\+)?\\d+(\\.\\d+)?$]eV/atom*',j))\n",
    "print(len(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    As a knowledgeable scientific assistant, your task is to analyze the text focusing on the Low Density of States (DOS) at the Fermi level for specific materials. The unit of Density of States (DOS) is \"eV/atom\" \n",
      "    Please provide the result as follows:\n",
      "    if the text contains a material has Density of States (DOS), please tell me the material name, its chemical formula and its Density of States (DOS)\n",
      "    if the text does not contain Density of States (DOS), please tell me \"No finds\"\n",
      "     V/atom)47, arsenene (-2.99 eV/atom\n",
      " Extract:\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "def generate_prompt(dialogue, summary=None, eos_token=\"</s>\"):\n",
    "    instruction = \"\"\"\n",
    "    As a knowledgeable scientific assistant, your task is to analyze the text focusing on the Low Density of States (DOS) at the Fermi level for specific materials. The unit of Density of States (DOS) is \"eV/atom\" \n",
    "    Please provide the result as follows:\n",
    "    if the text contains a material has Density of States (DOS), please tell me the material name, its chemical formula and its Density of States (DOS)\n",
    "    if the text does not contain Density of States (DOS), please tell me \"No finds\"\n",
    "    \"\"\"\n",
    "    \n",
    "    input = f\"{dialogue}\\n\"\n",
    "    summary = f\"Extract:\\n {summary + ' ' + eos_token if summary else ''} \"\n",
    "    prompt = (\" \").join([instruction, input, summary])\n",
    "    return prompt\n",
    "\n",
    "print(generate_prompt(target[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m input_tokens \u001b[38;5;241m=\u001b[39m tokenizer(input_prompt, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast():\n\u001b[0;32m----> 4\u001b[0m   generation_output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m      \u001b[49m\u001b[43mrepetition_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.15\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m      \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m      \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m op \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(generation_output[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(op\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m</\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1592\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1584\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1585\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1586\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   1587\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1588\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1589\u001b[0m     )\n\u001b[1;32m   1591\u001b[0m     \u001b[38;5;66;03m# 13. run sample\u001b[39;00m\n\u001b[0;32m-> 1592\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1593\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1594\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1598\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1599\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1600\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_logits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1601\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1602\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1604\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1605\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1607\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH:\n\u001b[1;32m   1608\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   1609\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   1610\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1611\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1616\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   1617\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:2734\u001b[0m, in \u001b[0;36mGenerationMixin.sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, output_logits, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2732\u001b[0m \u001b[38;5;66;03m# sample\u001b[39;00m\n\u001b[1;32m   2733\u001b[0m probs \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(next_token_scores, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m-> 2734\u001b[0m next_tokens \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultinomial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   2736\u001b[0m \u001b[38;5;66;03m# finished sentences should have their next token be a padding token\u001b[39;00m\n\u001b[1;32m   2737\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m eos_token_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_prompt = generate_prompt(target[90])\n",
    "input_tokens = tokenizer(input_prompt, return_tensors=\"pt\")[\"input_ids\"].to(\"cuda\")\n",
    "with torch.cuda.amp.autocast():\n",
    "  generation_output = model.generate(\n",
    "      input_ids=input_tokens,\n",
    "      max_new_tokens=1000,\n",
    "      do_sample=True,\n",
    "      top_k=10,\n",
    "      top_p=0.9,\n",
    "      temperature=0.3,\n",
    "      repetition_penalty=1.15,\n",
    "      num_return_sequences=1,\n",
    "      eos_token_id=tokenizer.eos_token_id,\n",
    "      pad_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "op = tokenizer.decode(generation_output[0], skip_special_tokens=True)\n",
    "print(op.split(\"</\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = op.split(\"</\")[0]\n",
    "# print(result)\n",
    "output = result.split(\"Extract:\\n\")[-1]\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "results = []\n",
    "df = pd.DataFrame({\n",
    "    'Number':[],\n",
    "    'Content':[],\n",
    "    'Output':[]\n",
    "})\n",
    "for i,j in enumerate(target):\n",
    "    print(i)\n",
    "    input_prompt = generate_prompt(j)\n",
    "    input_tokens = tokenizer(input_prompt, return_tensors=\"pt\")[\"input_ids\"].to(\"cuda\")\n",
    "    with torch.cuda.amp.autocast():\n",
    "      generation_output = model.generate(\n",
    "          input_ids=input_tokens,\n",
    "          max_new_tokens=1000,\n",
    "          do_sample=True,\n",
    "          top_k=10,\n",
    "          top_p=0.9,\n",
    "          temperature=0.3,\n",
    "          repetition_penalty=1.15,\n",
    "          num_return_sequences=1,\n",
    "          eos_token_id=tokenizer.eos_token_id,\n",
    "          pad_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "    op = tokenizer.decode(generation_output[0], skip_special_tokens=True)\n",
    "    # print(op.split(\"</\")[0])\n",
    "    result = op.split(\"</\")[0]\n",
    "    content = j\n",
    "    output = result.split(\"Extract:\\n\")[-1]\n",
    "    df.loc[len(df.index)] = [i, content, output]\n",
    "    \n",
    "    # if i >= 10:\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>Content</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>E (meV/atom</td>\n",
       "      <td>1. Material Name: \\n   2. Chemical Formula:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>E (meV/atom</td>\n",
       "      <td>1. The material's name.\\n   2. Its chemical...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hubbard U(eV)-1.5-1-0.50âˆ†E (meV/atom</td>\n",
       "      <td>2.8 eV/atom\\n   3.4 eV/atom\\n   6.7 eV/atom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Energy [eV/atom</td>\n",
       "      <td>1.0\\n   2.0\\n   3.0\\n   4.0\\n   5.0\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>E Bis -3.811 eV/atom</td>\n",
       "      <td>1. The density of states at the fermi energ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>V/atom)47, arsenene (-2.99 eV/atom</td>\n",
       "      <td>1. Material: Arsenene\\n   2. Chemical Formu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>While the EFormis found to be âˆ’0.69 eV, the EC...</td>\n",
       "      <td>The density of states at the Fermi energy w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>La 2.58Te4 is 23.7  meV/atom</td>\n",
       "      <td>La 2.58Te4 is 23.7  meV/atom\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>DOS (states/eV/atom</td>\n",
       "      <td>1. The material name.\\n   2. Its chemical f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>DOS (states/eV/atom</td>\n",
       "      <td>1. Material Name: \\n   2. Chemical Formula:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Convergence criteria included 10-5 eV/atom</td>\n",
       "      <td>The density of states (DOS) is calculated u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Number                                            Content  \\\n",
       "0        0                                        E (meV/atom   \n",
       "1        1                                        E (meV/atom   \n",
       "2        2               Hubbard U(eV)-1.5-1-0.50âˆ†E (meV/atom   \n",
       "3        3                                    Energy [eV/atom   \n",
       "4        4                               E Bis -3.811 eV/atom   \n",
       "5        5                 V/atom)47, arsenene (-2.99 eV/atom   \n",
       "6        6  While the EFormis found to be âˆ’0.69 eV, the EC...   \n",
       "7        7                       La 2.58Te4 is 23.7  meV/atom   \n",
       "8        8                                DOS (states/eV/atom   \n",
       "9        9                                DOS (states/eV/atom   \n",
       "10      10         Convergence criteria included 10-5 eV/atom   \n",
       "\n",
       "                                               Output  \n",
       "0      1. Material Name: \\n   2. Chemical Formula:...  \n",
       "1      1. The material's name.\\n   2. Its chemical...  \n",
       "2      2.8 eV/atom\\n   3.4 eV/atom\\n   6.7 eV/atom...  \n",
       "3             1.0\\n   2.0\\n   3.0\\n   4.0\\n   5.0\\n\\n  \n",
       "4      1. The density of states at the fermi energ...  \n",
       "5      1. Material: Arsenene\\n   2. Chemical Formu...  \n",
       "6      The density of states at the Fermi energy w...  \n",
       "7                    La 2.58Te4 is 23.7  meV/atom\\n\\n  \n",
       "8      1. The material name.\\n   2. Its chemical f...  \n",
       "9      1. Material Name: \\n   2. Chemical Formula:...  \n",
       "10     The density of states (DOS) is calculated u...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('DOS.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[128000,    198,    262,   1666,    264,  42066,  12624,  18328,     11,\n",
       "            701,   3465,    374,    311,  24564,    279,   1495,  21760,    389,\n",
       "            279,  12310,  73710,    315,   4273,    320,     35,   3204,      8,\n",
       "            520,    279,  99362,     72,   2237,    369,   3230,   7384,     13,\n",
       "           5321,   3493,    279,   1121,    439,  11263,    512,    262,    422,\n",
       "            279,   1495,   5727,    264,   3769,    706,  73710,    315,   4273,\n",
       "            320,     35,   3204,    705,   4587,   3371,    757,    279,   3769,\n",
       "            836,     11,   1202,  11742,  15150,    323,   1202,  73710,    315,\n",
       "           4273,    320,     35,   3204,    340,    262,    422,    279,   1495,\n",
       "           1587,    539,   6782,  73710,    315,   4273,    320,     35,   3204,\n",
       "            705,   4587,   3371,    757,    330,   2822,  14035,    702,    262,\n",
       "           6227,     11,    279,   5089,    315,  73710,    315,   4273,    320,\n",
       "             35,   3204,      8,    374,    330,     68,     53,     14,  22612,\n",
       "            702,    257,   1221,  81848,  13186,   5343,    220,    605,     12,\n",
       "             20,    384,     53,     14,  22612,    198,  23673,    512,    256]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('result', save_embedding_layers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for param in model.parameters():\n",
    "#     print(param.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, param in model.named_parameters():\n",
    "#     print(param.requires_grad, name, param.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify which parameters are trainable\n",
    "# for name, param in model.named_parameters():\n",
    "#     if param.requires_grad:\n",
    "#         print(f\"Trainable: {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, param in model.named_parameters():\n",
    "#     print(f\"Trainable: {name}\", param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.get_input_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.add_special_tokens({\"pad_token\": \"<PAD>\"})\n",
    "# model.resize_token_embeddings(len(tokenizer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
