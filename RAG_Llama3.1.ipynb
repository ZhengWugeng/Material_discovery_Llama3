{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6130e94-b517-4d7f-a514-1f50796e833b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model, PeftModel\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5b9fbcf-bda7-4523-b012-44f1ae8e7ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1,2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c3242fa-4c3d-4507-bd18-c50262ad7568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gilbert = pd.read_excel('gilbert_values.xlsx')\n",
    "# gilbert['text'] = 'The gilbert damping constant of ' + gilbert['material_name'] + ' is '+ gilbert['gilbert_damping_constant'].apply(lambda x: str(x))\n",
    "# gilbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e60dc6e5-4958-4059-b9a8-96869f070d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resistivity = pd.read_excel('Resistivity_Mag_Drop_duplicates.xlsx')\n",
    "# resistivity['text'] = 'The resistivity of ' + resistivity['Material_New'] + ' is '+ resistivity['Value'].apply(lambda x: str(x)) + 'Ohm.m'\n",
    "# resistivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c7312ce-9932-4eed-ae73-c2adfdd5132e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = pd.DataFrame(columns = ['text'])\n",
    "# dataset = pd.concat([dataset,resistivity['text']])\n",
    "# dataset = pd.concat([dataset,gilbert['text']])\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd897ab0-6ab8-47aa-8c6d-c62e5f94da92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.to_csv('value.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a8a7937-ca85-4de4-a4b1-049bfc6520de",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"ZWG817/Materials_Prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed85a207-dad7-4243-9bba-b91e20001dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ST = SentenceTransformer(\"mixedbread-ai/mxbai-embed-large-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56bae1ee-1c7c-4d4e-9a46-26323d15627c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(batch):\n",
    "    \"\"\"\n",
    "    adds a column to the dataset called 'embeddings'\n",
    "    \"\"\"\n",
    "    # or you can combine multiple columns here\n",
    "    # For example the title and the text\n",
    "    information = batch[\"text\"]\n",
    "    return {\"embeddings\" : ST.encode(information)}\n",
    "\n",
    "dataset = dataset.map(embed,batched=True,batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "478dfe82-47b1-4d5d-8c07-4e127c7f0614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4ab8039ffa44805a8c8213ced28eeeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = dataset[\"train\"]\n",
    "data = data.add_faiss_index(\"embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca988fbd-f75a-40f9-bf26-b28baebb49d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query: str, k: int = 3 ):\n",
    "    \"\"\"a function that embeds a new query and returns the most probable results\"\"\"\n",
    "    embedded_query = ST.encode(query) # embed new query\n",
    "    scores, retrieved_examples = data.get_nearest_examples( # retrieve results\n",
    "        \"embeddings\", embedded_query, # compare our new embedded query with the dataset embeddings\n",
    "        k=k # get only top k results\n",
    "    )\n",
    "    return scores, retrieved_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68a87f2f-e9a5-41e5-ac2b-a10a469ba62f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The gilbert damping constant of YIG is 7.35e-05',\n",
       " 'The gilbert damping constant of YIG YIG is 0.008']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores , result = search(\"yig\", 2 ) \n",
    "result['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db772ea1-7c1c-419d-9341-2430b5450aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"auto\",\n",
    "    )\n",
    "    model = model.bfloat16()\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13e2dff1-9df3-47d6-ba98-d4fa8e164b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7aa1478dfcd47829f23475e470444a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model_name = 'nvidia/Llama-3.1-Nemotron-70B-Instruct-HF'\n",
    "model_name = 'meta-llama/Llama-3.1-8B-Instruct'\n",
    "model, tokenizer = load_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58579c63-0790-427e-8939-e7399d899044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(128256, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0df622a5-3334-4075-b9c4-9b92ec539691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_prompt(prompt,retrieved_documents,k):\n",
    "  \"\"\"using the retrieved documents we will prompt the model to generate our responses\"\"\"\n",
    "  PROMPT = f\"Question:{prompt}\\nContext:\"\n",
    "  for idx in range(k) :\n",
    "    PROMPT+= f\"{retrieved_documents['text'][idx]}\\n\"\n",
    "  return PROMPT\n",
    "\n",
    "def generate(formatted_prompt):\n",
    "  formatted_prompt = formatted_prompt\n",
    "  messages = [{\"role\":\"system\",\"content\":SYS_PROMPT1},\n",
    "              {\"role\":\"system\",\"content\":SYS_PROMPT2},\n",
    "              {\"role\":\"user\",\"content\":formatted_prompt}]\n",
    "  # tell the model to generate\n",
    "  input_ids = tokenizer.apply_chat_template(\n",
    "      messages,\n",
    "      add_generation_prompt=True,\n",
    "      return_tensors=\"pt\"\n",
    "  ).to(model.device)\n",
    "  outputs = model.generate(\n",
    "      input_ids,\n",
    "      max_new_tokens=1024,\n",
    "      eos_token_id=[\n",
    "          tokenizer.eos_token_id,\n",
    "          tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "      ],\n",
    "      do_sample=True,\n",
    "      temperature=0.6,\n",
    "      top_p=0.9,\n",
    "  )\n",
    "  response = outputs[0][input_ids.shape[-1]:]\n",
    "  return tokenizer.decode(response, skip_special_tokens=True)\n",
    "\n",
    "def rag_chatbot(prompt:str,k:int=2):\n",
    "  scores , retrieved_documents = search(prompt, k)\n",
    "  formatted_prompt = format_prompt(prompt,retrieved_documents,k)\n",
    "  return generate(formatted_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ea3d22e-e818-4b5f-9c35-a37fab42f8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYS_PROMPT1 = \"\"\"You are an assistant for answering questions.\n",
    "You are given the extracted parts of a long document and a question. Provide a conversational answer.\n",
    "If you don't know the answer, please make an inference based on the data given\"\"\"\n",
    "\n",
    "SYS_PROMPT2 = \"\"\"The data provide is the gilbert damping constant and material resistivity about materials. Usually, high resistivity would lead to low gilbert damping constant. Now Please Answer the question below:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d530c645-c102-4cab-a91a-53fa0ed49fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Based on the provided data, we can infer that materials with high resistivity tend to have low Gilbert damping constants. With this in mind, let's propose five new magnetic materials with extremely low Gilbert damping constants:\\n\\n1. **Material Formula:** Y2Ir3Fe5O12\\n**Gilbert Damping Constant:** 1e-06 (predicted to be extremely low due to high resistivity and similarity to Y3Fe5O12)\\nYttrium (Y) is a good candidate for creating materials with low Gilbert damping constants, as seen in Y3Fe5O12. Adding Ir (Iridium) to the formula may further increase the resistivity and reduce the Gilbert damping constant.\\n\\n2. **Material Formula:** Mn2V3Fe5SiO12\\n**Gilbert Damping Constant:** 5e-07 (predicted to be extremely low due to high resistivity and similarity to MnSi)\\nManganese (Mn) is known for its high resistivity, and adding V (Vanadium) and Si (Silicon) may further increase the resistivity and reduce the Gilbert damping constant.\\n\\n3. **Material Formula:** Co2Ti3Fe5SiO12\\n**Gilbert Damping Constant:** 1e-06 (predicted to be extremely low due to high resistivity and similarity to CoFe/NiFe)\\nCobalt (Co) is a good candidate for creating materials with low Gilbert damping constants, as seen in CoFe/NiFe. Adding Ti (Titanium) and Si (Silicon) may further increase the resistivity and reduce the Gilbert damping constant.\\n\\n4. **Material Formula:** Fe2Ir3Ge5\\n**Gilbert Damping Constant:** 5e-07 (predicted to be extremely low due to high resistivity and similarity to Fe2CoSi)\\nIron (Fe) is a good candidate for creating materials with low Gilbert damping constants, as seen in Fe2CoSi. Adding Ir (Iridium) and Ge (Germanium) may further increase the resistivity and reduce the Gilbert damping constant.\\n\\n5. **Material Formula:** Ni2V3Fe5SiO12\\n**Gilbert Damping Constant:** 1e-06 (predicted to be extremely low due to high resistivity and similarity to Ni45Fe55)\\nNickel (Ni) is known for its high resistivity, and adding V (Vanadium) and Si (Silicon) may further increase the resistivity and reduce the Gilbert damping constant.\\n\\nPlease note that these predictions are based on the provided data and may not reflect the actual properties of these materials. Experimental verification is necessary to confirm these predictions.\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chatbot(\"Please list the prediction for at least 5 new magnetic materials (completely new) with extremely low gilbert damping. Make sure provide its material formula\", k = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07642dc-787c-40fa-8a36-8e99e71c5e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
